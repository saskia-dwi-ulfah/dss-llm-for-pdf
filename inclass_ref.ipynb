{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSS May 2024: Efficient Information Extraction: Q&A and Summarization over PDF Documents using LLM\n",
    "\n",
    "* Instruktur: [Saskia Dwi Ulfah](https://www.linkedin.com/in/saskia-dwi-ulfah/).\n",
    "* Last updated: May 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìï Dokumen yang disimpan dalam format **Portable Document Format (PDF)** merupakan salah satu bentuk dokumen yang sering digunakan untuk bertukar informasi melalui internet dan perangkat digital seperti handphone, laptop, dan komputer. PDF juga dimanfaatkan di berbagai sektor. Di bidang pendidikan, mahasiswa dapat mengakses jurnal penelitian dengan format PDF melalui website seperti Elsevier dan IEEE. Di bidang finansial, perusahaan menampilkan laporan keuangan tahunan dalam format PDF pada website perusahaan.\n",
    "\n",
    "\n",
    "‚õ≥ Format PDF merupakan format yang universal. Artinya, dokumen yang disimpan dalam format PDF dapat diakses secara mudah pada perangkat yang berbeda. Selain itu, format PDF lebih disukai karena tampilan dokumen yang lebih rapi dibandingkan format dokumen lainnya. PDF juga men-support dokumen yang terdiri lebih dari satu halaman. Hal ini memungkinkan pengguna untuk menuliskan informasi yang lengkap dan komprehensif dalam sebuah dokumen PDF. Akan tetapi, hal ini membuat **dokumen PDF cenderung tebal dan kompleks** sehingga menyebabkan pembaca **kesulitan untuk menemukan informasi yang spesifik**.\n",
    "\n",
    "üí° Dengan perkembangan teknologi artificial intelligence  (AI) dan machine learning (ML), kita dapat menggunakan **Large Language Model (LLM)** untuk pencarian informasi pada dokumen PDF. Pada workshow ini, Anda akan belajar bagaimana kita dapat memperluas kemampuan LLM untuk pencarian informasi secara efisien dari dokumen PDF. Dimulai dengan dokumen PDF biasa, Anda akan belajar cara memproses dokumen ini dan menyajikannya sebagai konteks tambahanuntuk LLM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ Setelah menyelesaikan workshop ini, Anda diharapkan dapat:\n",
    "\n",
    "* Memahami konsep dasar dari LLM.\n",
    "* Mengimplementasikan penggunaan LLM dengan framework LangChain.\n",
    "* Memahami workflow yang digunakan dalam menyediakan additional context untuk LLM.\n",
    "* Mengembangkan skill di bidang AI dan data science dengan menguasai teknik information retrieval dari dokumen PDF menggunakan LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Syllabus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Python Programming Basics** \n",
    "    - Introduction to Python for Data Science.\n",
    "    - Working with Python Environment.\n",
    "    - Working with Notebook.\n",
    "    - Python Fundamental Data Types and Data Structures.\n",
    "    - Understanding Looping Concept in Python.\n",
    "    - Understanding The Creation of Python Function.\n",
    "    - Understanding The Usage of Python Libraries.\n",
    "* **The Fundamentals of LLM**\n",
    "    - The Concept of Generative AI.\n",
    "    - LLM as Generative AI.\n",
    "    - Transformer Architecture in a Nutshell\n",
    "    - LLM Capability, Limitation, and Consideration\n",
    "* **Introduction to LangChain**\n",
    "    - The Big Picture of LangChain Concept and Component\n",
    "    - API Concept and Setting for LangChain Usage\n",
    "    - Demonstration of LLM Usage with LangChain\n",
    "* **Case Study: Q&A and Summarization for PDF Document**\n",
    "    - The Concept of RAG (Retrieval Augmented Generation)\n",
    "    - Loading PDF Documents using LangChain\n",
    "    - The Concept of Embedding for PDF Documents\n",
    "    - Storing The Embedding using a Vector Database\n",
    "    - Prompt Creation for Q&A and Summarization Cases\n",
    "    - Employing LLM for Information Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Programming Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Python for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üêç **Python** merupakan bahasa pemrograman yang banyak digunakan untuk data science dan artificial intelligence. Bahasa pemrograman ini dirancang oleh Guido van Rossum dan pertama kali dirilis pada tahun 1991.\n",
    "\n",
    "Beberapa fitur yang menjadi keunggulan Python:\n",
    "- Sintaks yang intuitif dan mudah dipelajari.\n",
    "- Ketersediaan library dan framework yang kaya dan informatif. Beberapa library yang sering digunakan di Python.\n",
    "    * Pandas: untuk mengolah data dalam bentuk dataframe.\n",
    "    * Numpy: untuk proses matematika yang melibatkan matriks.\n",
    "    * Matplotlib dan Seaborn: untuk visualisasi data.\n",
    "    * Scikit-learn: untuk membuat model machine learning.\n",
    "    * PyTorch dan Tensorflow: untuk membuat model deep learning.\n",
    "    * **Langchain**: untuk membuat aplikasi berbasis LLM.\n",
    "\n",
    "> üìå [Python 3.10 Official Documentation](https://docs.python.org/3.10/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Python Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/venv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üè§ **Virtual environment** adalah environment terisolasi yang memungkinkan setiap environment memiliki instalasi dan versi package yang khusus dan berbeda. Kita bisa menggunakan virtual environment saat memiliki banyak projek di mana setiap projek membutuhkan package dengan versi yang spesifik. Dengan menggunakan virtual environment, kita bisa menjalankan berbagai macam projek pada satu device yang sama tanpa perlu khawatir akan adanya permasalahan yang timbul karena perbedaan versi package (dependency conflict)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öôÔ∏è **Membuat Virtual Environment Baru**\n",
    "\n",
    "1. Buka terminal baru. Pilih menu `Terminal` dan pilih menu `New Terminal`.\n",
    "\n",
    "![](assets/terminal_menu.png)\n",
    "\n",
    "2. Membuat environmet baru dengan nama `dss_may2024` dengan Python versi 3.10.\n",
    "   * Sintaks: `conda create -n dss_may2024 python==3.10`.\n",
    "   * Tunggu hingga proses pembuatan virtual environment selesai.\n",
    "\n",
    "![](assets/make_venv.png)\n",
    "\n",
    "3. Aktifkan environment yang sudah dibuat.\n",
    "   * Sintaks: `conda activate dss_may2024`.\n",
    "\n",
    "![](assets/activate_venv.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öôÔ∏è **Meng-install Library yang Diperlukan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah membuat virtual environment, kita akan meng-install semua library yang akan digunakan pada workshop kali ini. \n",
    "\n",
    "* Meng-install banyak library sekaligus: dengan file `requirements.txt`.\n",
    "  * Sintaks: `pip install -r requirements.txt`.\n",
    "\n",
    "![](assets/install_req.png)\n",
    "\n",
    "* Meng-install 1 library.\n",
    "  * Sintaks: `pip install <PACKAGE_NAME>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown and Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File yang sedang kita gunakan saat ini  disebut dengan **notebook**. Notebook merupakan file Python dengan format `.ipynb` yang memungkinkan kita untuk menulis kode Python dan memberikan penjelasan secara interaktif pada cell. Terdapat 2 jenis cell pada notebook:\n",
    "\n",
    "* **Markdown**\n",
    "    * Untuk menuliskan narasi.\n",
    "    * Kita bisa menulis teks **bold**, *italic*, bahkan formula matematis seperti:\n",
    "\n",
    "    $$f(x) = \\frac{e^{-x}}{(1+e^{-x})}$$\n",
    "\n",
    "* **Code**\n",
    "    * Untuk menuliskan kode Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Language Model\n"
     ]
    }
   ],
   "source": [
    "# print(\"Ini adalah code cell\") --> tidak akan dieksekusi oleh Python\n",
    "\n",
    "print(\"Large Language Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command and Edit Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terdapat 2 mode cell dalam notebook:\n",
    "\n",
    "1. **Command Mode**\n",
    "    - `a` : menambah cell baru di atas.\n",
    "    - `b` : menambah cell baru di bawah.\n",
    "    - `d` + `d` : menghapus cell terpilih.\n",
    "    - `c` : menyalin cell terpilih.\n",
    "    - `v` : paste cell terpilih.\n",
    "    - `m` : mengubah tipe cell ke markdown.\n",
    "    - `y` : mengubah tipe cell ke kode.\n",
    "    - `enter` : enter edit mode.\n",
    "\n",
    "\n",
    "2. **Edit Mode (Cell Terdapat Border Biru Persegi Panjang)**\n",
    "    - `Ctrl + Enter`: eksekusi satu cell.\n",
    "    - `Esc`: mengubah edit mode menjadi command mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Variable and Data Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saat menggunakan Python, sebagian besar pekerjaan kita melibatkan penyimpanan nilai tertentu dalam variabel. Untuk menyimpan nilai ke sebuah variabel, kita menggunakan assignment operator (`=`). \n",
    "\n",
    "Sebagai contoh, kita mendefinisikan variabel `activity` untuk menyimpan nilai `\"programming\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = \"programming\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penting untuk diperhatikan bahwa nama variabel dapat menyertakan angka, tetapi tidak boleh dimulai dengan angka. Memulai nama variabel dengan angka akan menimbulkan pesar error. \n",
    "\n",
    "Pada kode di bawah ini, kita mencoba mendefinisikan variabel `1activity`. \n",
    "\n",
    "Kita menggunakan simbol `#` untuk mengomentari bagian dari kode. Bagian yang dikomentari ini tidak akan dieksekusi. `#` dapat digunakan apabila kita ingin memberi penjelasan kode yang sudah dibuat. \n",
    "\n",
    "Untuk melihat pesan error yang muncul, hapus `#` pada baris pertama kode di bawah ini.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1activity = \"playing\"\n",
    "# menampilkan pesan SyntaxError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setiap nilai yang tersimpan dalam variabel memiliki tipe data tertentu. Terdapat tiga tipe data yang sering dijumpai di Python:\n",
    "\n",
    "* Tipe data untuk menyimpan nilai teks: `str`.\n",
    "* Tipe data untuk menyimpan nilai numerik: `int` dan `float`. \n",
    "  > Penting untuk diperhatikan bahwa tipe `float` disediakan untuk angka floating-point (berkoma).\n",
    "* Tipe data untuk menyimpan nilai kebenaran: `bool`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk memverifikasi tipe sebuah variabel, kita dapat memasukkan variabel tersebut ke dalam fungsi built-in `type()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studying\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# string dengan kutip 1\n",
    "str1 = 'Studying' # str type\n",
    "print(str1)\n",
    "print(type(str1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judul DSS bulan ini: 'Efficient Information Extraction: Q&A and Summarization over PDF Documents using LLM'\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# string dengan kutip 2\n",
    "str2 = \"Judul DSS bulan ini: 'Efficient Information Extraction: Q&A and Summarization over PDF Documents using LLM'\"\n",
    "print(str2)\n",
    "print(type(str2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ini adalah contoh string kutip 3. Kita dapat menulis kalimat dengan lebih rapi pada baris baru.\n",
      "\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# string dengan kutip 3\n",
    "str3 = ''' Ini adalah contoh string kutip 3. Kita dapat menulis kalimat dengan lebih rapi pada baris baru.\n",
    "'''\n",
    "print(str3)\n",
    "print(type(str3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "b = 10 # int type\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "c = 10.0 # float type\n",
    "print(type(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Operasi pada Angka** \n",
    "\n",
    "- `+`: penjumlahan.\n",
    "- `-`: pengurangan.\n",
    "- `*`: perkalian.\n",
    "- `/`: pembagian.\n",
    "- `//`: pembagian dengan pembulatan.\n",
    "- `%`: sisa pembagian.\n",
    "- `**`: eksponen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "12\n",
      "45\n",
      "5.0\n",
      "5\n",
      "0\n",
      "3375\n"
     ]
    }
   ],
   "source": [
    "print(15 + 3) # penjumlahan  \n",
    "print(15 - 3) # pengurangan \n",
    "print(15 * 3) # perkalian \n",
    "print(15 / 3) # pembagian \n",
    "print(15 // 3) # pembagian dengan pembulatan\n",
    "print(15 % 3) # sisa pembagian\n",
    "print(15 ** 3) # eksponen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "d = True # bool type\n",
    "print(type(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python bersifat **case-sensitive**. `\"Activity\"` dan `\"activity\"` adalah nilai yang berbeda. \n",
    "\n",
    "Pada kode di bawah ini, kita menggunakan operator `==` untuk membandingkan kesetaraan kedua nilai tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'activity' == 'Activity'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Output dari kode di atas adalah `False`. Hal ini menandakan kedua nilai tersebut berbeda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operator perbandingan lainnya:\n",
    "\n",
    "- `<`: lebih kecil dari (yaitu : a < b).\n",
    "- `<=`: lebih kecil atau sama dengan (yaitu : a <= b).\n",
    "- `>`: lebih besar dari (yaitu: a > b).\n",
    "- `>=`: lebih besar atau sama dengan (yaitu: a >= b).\n",
    "- `!=`: tidak sama dengan (yaitu: a != b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(15 < 3) \n",
    "print(15 <= 3)  \n",
    "print(15 > 3)  \n",
    "print(15 >= 3) \n",
    "print(15 != 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beberapa hal yang perlu diperhatikan: `True` dan  `False` termasuk dalam daftar istilah yang disebut sebagai **Python keywords**. Kita tidak dapat menggunakan keywords ini sebagai nama variabel, nama fungsi, atau memberikan nilai kepada mereka (melakukan assignment).\n",
    "\n",
    "Berikut adalah daftar keywords lainnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['False',\n",
       " 'None',\n",
       " 'True',\n",
       " 'and',\n",
       " 'as',\n",
       " 'assert',\n",
       " 'async',\n",
       " 'await',\n",
       " 'break',\n",
       " 'class',\n",
       " 'continue',\n",
       " 'def',\n",
       " 'del',\n",
       " 'elif',\n",
       " 'else',\n",
       " 'except',\n",
       " 'finally',\n",
       " 'for',\n",
       " 'from',\n",
       " 'global',\n",
       " 'if',\n",
       " 'import',\n",
       " 'in',\n",
       " 'is',\n",
       " 'lambda',\n",
       " 'nonlocal',\n",
       " 'not',\n",
       " 'or',\n",
       " 'pass',\n",
       " 'raise',\n",
       " 'return',\n",
       " 'try',\n",
       " 'while',\n",
       " 'with',\n",
       " 'yield']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cek daftar keywords\n",
    "import keyword\n",
    "\n",
    "keyword.kwlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebelumnya, kita sudah melihat tipe data apa yang dapat dimiliki oleh variabel di Python. Untuk keperluan tingkat lanjut, Python memiliki beberapa **data structure** untuk menyimpan beberapa tipe data secara bersamaan. Terdapat 2 **data structure** yang sering digunakan: list dan dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List** merupakan data structure yang memungkinkan kita untuk menyimpan beberapa nilai dengan tipe data yang berbeda. Untuk membuat list, kita menggunakan kurung siku (`[ ]`). Misalnya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_example = [\"Taylor Swift\",\n",
    "                34, \n",
    "                ['Shake It Off','Blank Space','Lover'],\n",
    "                True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Taylor Swift', 34, ['Shake It Off', 'Blank Space', 'Lover'], True]\n"
     ]
    }
   ],
   "source": [
    "print(list_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk mengakses nilai yang terdapat di dalam list, kita menggunakan **indeks/posisi** dari nilai tersebut.\n",
    "\n",
    "> ‚ÑπÔ∏è Python menerapkan **zero-indexing**. Posisi pertama memiliki indeks 0, posisi kedua memiliki indeks 1, dan seterusnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mengakses usia Taylor Swift: posisi 2, indeks 1\n",
    "\n",
    "list_example[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jika kita ingin mengakses beberapa nilai dalam list sekaligus, kita bisa menggunakan `:`. Misalnya, kita ingin mengakses nama, usia, dan daftar lagu yang populer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Taylor Swift', 34, ['Shake It Off', 'Blank Space', 'Lover']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_example[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dengan kode di atas, kita hanya menampilkan data dengan indeks 0-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cara lain untuk mengakses nilai di dalam list adalah menggunakan **back indexing**. Dengan back indexing, kita menggunakan nilai negatif untuk mengakses nilai di dalam list dari belakang. Misalnya, jika kita memasukkan indeks -1, kita akan menampilkan item terakhir dari list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# item terakhir di list\n",
    "list_example[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shake It Off', 'Blank Space', 'Lover']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mengakses daftar lagu populer\n",
    "list_example[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada list, kita menggunakan indeks untuk mengakses sebuah nilai. Pada **dictionary** kita menggunakan **key** untuk mengakses sebuah nilai/**value**. Untuk membuat sebuah dictionary, kita menggunakan kurung keriting (`{ }`). Misalnya:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_example = {\n",
    "    \"name\" : \"Taylor Swift\",\n",
    "    \"age\" : 34,\n",
    "    \"popular_songs\" : ['Shake It Off','Blank Space','Lover']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Taylor Swift',\n",
       " 'age': 34,\n",
       " 'popular_songs': ['Shake It Off', 'Blank Space', 'Lover']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dict_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dengan contoh di atas:\n",
    "\n",
    "* Yang merupakan key adalah `\"name\"`, `\"age\"`, dan `\"popular_songs\"`.\n",
    "* Yang merupakan value adalah `\"Taylor Swift\"`, `34`, dan `['Shake It Off', 'Blank Space', 'Lover']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk mengakses usia Taylor Swift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mengakses usia dengan key \"age\"\n",
    "dict_example['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping (`while`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîÅ **Looping** pada Python merupakan eksekusi kode secara berulang sampai suatu kondisi terpenuhi. Salah satu sintaks untuk melakukan looping di Python adalah `while`. Contoh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ini adalah iterasi ke 1\n",
      "Ini adalah iterasi ke 2\n",
      "Ini adalah iterasi ke 3\n",
      "Ini adalah iterasi ke 4\n",
      "Ini adalah iterasi ke 5\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "\n",
    "while i <= 5:\n",
    "    print(f\"Ini adalah iterasi ke {i}\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ‚ÑπÔ∏è `f` pada saat menampilkan kalimat di atas disebut dengan **F-string**. Sederhananya, F-string memungkinkan kita untuk menampilkan nilai dari sebuah variabel secara dinamis dalam sebuah kalimat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada kode di atas:\n",
    "\n",
    "* Kita mendefinisikan kondisi awal, `i = 1`.\n",
    "* Pengecekan kondisi, apakah nilai `i` saat ini kecil atau sama dengan 5.\n",
    "  * Jika benar, maka akan ditampilkan tulisan dan nilai `i` akan bertambah 1. \n",
    "  * Jika tidak, proses iterasi akan berakhir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function** pada Python merupakan blok kode yang dapat digunakan secara berulang. Penggunaan function dapat membuat penulisan kode kita menjadi lebih rapi dan tidak redundan. \n",
    "\n",
    "Function pada Python umumnya memiliki 3 komponen utama:\n",
    "\n",
    "* **Parameter**: input untuk function.\n",
    "* **Block of code**: blok kode untuk melakukan operasi pada input.\n",
    "* **Return value**: output hasil operasi function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk mendefinisikan function, kita menggunakan keywords `def`. Misalnya, kita membuat sebuah function untuk melakukan beberapa operasi matematika sekaligus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def math_ops(num1, num2, num3):\n",
    "    sum = num1 + num2 + num3\n",
    "    sub = num1 - num2 - num3\n",
    "\n",
    "    print(f\"Angka: {num1}, {num2}, {num3}\")\n",
    "    print(f\"Hasil penjumlahan: {sum}\")\n",
    "    print(f\"Hasil pengurangan: {sub}\")\n",
    "\n",
    "    return sum, sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angka: 100, 15, 25\n",
      "Hasil penjumlahan: 140\n",
      "Hasil pengurangan: 60\n"
     ]
    }
   ],
   "source": [
    "hasil_jumlah, hasil_kurang = math_ops(100, 15, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print(hasil_jumlah)\n",
    "print(hasil_kurang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salah satu kelebihan Python adalah tersedianya banyak **package** atau **library** yang dapat kita gunakan dengan mudah. Kita dapat menganggap library sebagai sekumpulan fungsi/program yang telah ditulis orang lain dan dapat kita gunakan kembali. Untuk dapat menggunakan fungsi yang terdapat dalam suatu library, kita harus meng-import library tersebut. \n",
    "\n",
    "Terdapat 2 cara paling umum untuk meng-import library:\n",
    "\n",
    "* Import library dengan statement `import`. Penggunaan fungsi/class menyertakan nama library.\n",
    "\n",
    "```python\n",
    "# cara import library\n",
    "import langchain_community.document_loaders\n",
    "\n",
    "# cara memanggil function/class\n",
    "pdf_loader = langchain_community.document_loaders.PyPDFLoader()\n",
    "\n",
    "```\n",
    "\n",
    "* Import fungsi langsung dengan statement `from`. Penggunaan fungsi/class tidak menyertakan nama library.\n",
    "\n",
    "```python\n",
    "# cara import library\n",
    "from langchain_community.document_loaders import PyPDFLoader()\n",
    "\n",
    "# cara memanggil function/class\n",
    "pdf_loader = PyPDFLoader()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Fundamentals of LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Concept of Generative AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/gen_ai_hierarchy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üöÄ **Apa itu Generative AI?**\n",
    "\n",
    "**Generative AI** merupakan bagian dari artificial intelligence yang bertujuan untuk **menghasilkan (generate) data**, seperti teks, gambar, video, dan musik. Untuk dapat menghasilkan data, generative AI dilatih/belajar dari data yang jumlahnya sangat besar. Proses belajar ini sering disebut training. Generative AI akan menghasilkan data berdasarkan pola yang sudah dipelari selama proses training.\n",
    "\n",
    "üöÄ **Jenis-Jenis Generative AI dan Aplikasinya**\n",
    "\n",
    "1. **Generative Text Model**\n",
    "    * Input: teks.\n",
    "    * Output ‚Üí teks (text-to-text generator).\n",
    "      * Contoh: translation, **summarization**, **question-answering**, grammar correction.\n",
    "    * Output ‚Üí image (text-to-image generator).\n",
    "      * Contoh: image generation, video generation.\n",
    "    * Output ‚Üí audio (text-to-speech generator).\n",
    "2. **Generative Image Model**\n",
    "    * Input: gambar.\n",
    "    * Output: teks (image-to-text generator).\n",
    "      * Contoh: image captioning, visual question-answering, image search.\n",
    "    * Output: gambar (image-to-image generator).\n",
    "      * Contoh: image completion.\n",
    "    * Output: video (image-to-video generator).\n",
    "      * Contoh: animation generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM as Generative AI \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí¨ **LLM** merupakan generative AI yang telah dilatih menggunakan data teks dalam jumlah yang sangat besar. LLM mampu untuk memahami dan menghasilkan teks dengan gaya bahasa yang mirip dengan manusia. Selain menggambarkan besarnya data yang digunakan untuk melatih LLM, istilah \"large\" mengacu kepada tingkat kompleksitas, ukuran, dan banyaknya parameter pada LLM.\n",
    "\n",
    "> ‚ÑπÔ∏è Sebagai contoh, GPT-4, varian yang paling baru dari LLM yang dirilis oleh OpenAI, memiliki 1,3 triliun parameter. Sumber data yang digunakan untuk melatih model ini meliputi buku, website, jurnal ilmiah, artikel, posting-an media sosial, dan repositori kode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jenis-Jenis LLM**\n",
    "\n",
    "üí¨ Beberapa contoh platform LLM yang populer: \n",
    "\n",
    "1. **GPT**\n",
    "\n",
    "Generative Pre-Trained Transformer (GPT) merupakan large language model yang dikembangkan oleh Open AI. Sama seperti model generative AI lainnya, GPT di-training dengan data teks dalam jumlah yang besar. \n",
    "\n",
    "\n",
    "2. **Gemini**\n",
    "\n",
    "**Gemini** merupakan model generative AI yang dikembangkan oleh Google. Gemini dilatih menggunakan data teks, gambar, suara, dan video secara bersamaan dalam jumlah yang sangat besar. Hal ini membuat Gemini mampu untuk menerima berbagai macam input. Kelebihan ini menjadikan Gemini unggul dari segi generalisasinya terhadap data baru. Saat ini, versi terbaru dari Gemini adalah Gemini 1.5. \n",
    "\n",
    "Secara umum, fitur-fitur pada Gemini dikemas dalam 2 bentuk produk. Produk yang pertama merupakan [aplikasi yang berbasis chat bernama Gemini app (sebelumnya Bard)](https://gemini.google.com/app). Penggunaan aplikasi ini ditujukan untuk siapa saja secara umum tanpa perlu menuliskan kode tertentu. Produk lainnya merupakan [Application Programming Interface (API)](https://ai.google.dev/gemini-api) yang dapat digunakan pada use case yang lebih custom. Penggunaan API ini lebih ditujukan untuk para developer.\n",
    "\n",
    "3. **HuggingFace**\n",
    "\n",
    "---add description---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompt pada Language Model**\n",
    "\n",
    "---add basic prompt engineering---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Architecture in a Nutshell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§ñ Arsitektur **Transformer** merupakan salah satu fondasi dibalik keandalan LLM. Arsitektur ini pertama kali diperkenalkan pada paper yang berjudul [Attention is All You Need](https://arxiv.org/abs/1706.03762) oleh Vaswani dkk. pada tahun 2017. \n",
    "\n",
    "Kemunculan arsitektur Transformer bertolak dari keterbatasan dari arsitektur yang sebelumnya sering digunakan untuk memodelkan data berupa sequence (contoh: bahasa), seperti Recurrent Neural Network (RNN) dan Long Short-Term Memory (LSTM). Keterbatasan ini di antaranya: ketidakefisienan dari segi daya komputasi dan waktu serta ketersediaan memori yang terbatas untuk sequence yang cukup panjang. Transformer mengatasi keterbatasan ini dengan fitur spesial yang disebut dengan **self-attention mechanism**. \n",
    "\n",
    "Secara sederhana, Transformer terdiri dari 2 komponen utama:\n",
    "\n",
    "1. **Encoder**\n",
    "2. **Decoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Capability, Limitation, and Consideration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LangChainü¶úüîó"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü¶úüîó**LangChain** merupakan framework untuk membuat aplikasi berbasis LLM.\n",
    "\n",
    "> üìå[LangChain Official Documentation](https://python.langchain.com/v0.1/docs/get_started/introduction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Concept and Component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM and Chat Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Concept and Setting for LangChain Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration of LLM Usage with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study: Q&A and Summarization for PDF Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untuk loading file PDF\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyPDFLoader('data_input/llm_survey.pdf',\n",
    "                         extract_images = True)\n",
    "pdf_data = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='3\\n(i.e.,following the scaling law [30]). A number of studies\\nhave explored the performance limit by training an ever\\nlarger PLM ( e.g., the 175B-parameter GPT-3 and the 540B-\\nparameter PaLM). Although scaling is mainly conducted\\nin model size (with similar architectures and pre-training\\ntasks), these large-sized PLMs display different behaviors\\nfrom smaller PLMs ( e.g., 330M-parameter BERT and 1.5B-\\nparameter GPT-2) and show surprising abilities (called emer-\\ngent abilities [31]) in solving a series of complex tasks. For\\nexample, GPT-3 can solve few-shot tasks through in-context\\nlearning , whereas GPT-2 cannot do well. Thus, the research\\ncommunity coins the term ‚Äú large language models (LLM) ‚Äù1\\nfor these large-sized PLMs [32‚Äì35], which attract increasing\\nresearch attention (See Figure 1). A remarkable application\\nof LLMs is ChatGPT2that adapts the LLMs from the GPT\\nseries for dialogue, which presents an amazing conversation\\nability with humans. We can observe a sharp increase of the\\narXiv papers that are related to LLMs after the release of\\nChatGPT in Figure 1.\\nAs discussed before, language model is not a new tech-\\nnical concept specially for LLMs, but has evolved with the\\nadvance of artificial intelligence over the decades. Early lan-\\nguage models mainly aim to model and generate text data,\\nwhile latest language models ( e.g., GPT-4) focus on complex\\ntask solving. From language modeling totask solving , it is an\\nimportant leap in scientific thinking, which is the key to\\nunderstand the development of language models in the re-\\nsearch history. From the perspective of task solving, the four\\ngenerations of language models have exhibited different lev-\\nels of model capacities. In Figure 2, we describe the evolu-\\ntion process of language models in terms of the task solving\\ncapacity. At first, statistical language models mainly assisted\\nin some specific tasks ( e.g., retrieval or speech tasks), in\\nwhich the predicted or estimated probabilities can enhance\\nthe performance of task-specific approaches. Subsequently,\\nneural language models focused on learning task-agnostic\\nrepresentations ( e.g., features), aiming to reduce the efforts\\nfor human feature engineering. Furthermore, pre-trained\\nlanguage models learned context-aware representations that\\ncan be optimized according to downstream tasks. For the\\nlatest generation of language model, LLMs are enhanced by\\nexploring the scaling effect on model capacity, which can be\\nconsidered as general-purpose task solvers. To summarize,\\nin the evolution process, the task scope that can be solved\\nby language models have been greatly extended, and the\\ntask performance attained by language models have been\\nsignificantly enhanced.\\nIn the existing literature, PLMs have been widely dis-\\ncussed and surveyed [36‚Äì39], while LLMs are seldom re-\\nviewed in a systematic way. To motivate our survey, we first\\nhighlight three major differences between LLMs and PLMs.\\nFirst, LLMs display some surprising emergent abilities that\\nmay not be observed in previous smaller PLMs. These abili-\\nties are key to the performance of language models on com-\\nplex tasks, making AI algorithms unprecedently powerful\\nand effective. Second, LLMs would revolutionize the way\\nthat humans develop and use AI algorithms. Unlike small\\n1. Note that a LLM is not necessarily more capable than a small PLM,\\nand emergent abilities may not occur in some LLMs.\\n2. https://openai.com/blog/chatgpt/PLMs, the major approach to accessing LLMs is through\\nthe prompting interface ( e.g., GPT-4 API). Humans have to\\nunderstand how LLMs work and format their tasks in a way\\nthat LLMs can follow. Third, the development of LLMs no\\nlonger draws a clear distinction between research and en-\\ngineering. The training of LLMs requires extensive practical\\nexperiences in large-scale data processing and distributed\\nparallel training. To develop capable LLMs, researchers\\nhave to solve complicated engineering issues, working with\\nengineers or being engineers.\\nNowadays, LLMs are posing a significant impact on\\nthe AI community, and the advent of ChatGPT and GPT-4\\nleads to the rethinking of the possibilities of artificial general\\nintelligence (AGI). OpenAI has published a technical article\\nentitled ‚Äú Planning for AGI and beyond ‚Äù, which discusses\\nthe short-term and long-term plans to approach AGI [40],\\nand a more recent paper has argued that GPT-4 might be\\nconsidered as an early version of an AGI system [41]. The\\nresearch areas of AI are being revolutionized by the rapid\\nprogress of LLMs. In the field of NLP , LLMs can serve as a\\ngeneral-purpose language task solver (to some extent), and\\nthe research paradigm has been shifting towards the use\\nof LLMs. In the field of IR, traditional search engines are\\nchallenged by the new information seeking way through AI\\nchatbots ( i.e.,ChatGPT), and New Bing3presents an initial\\nattempt that enhances the search results based on LLMs. In\\nthe field of CV , the researchers try to develop ChatGPT-like\\nvision-language models that can better serve multimodal\\ndialogues [42‚Äì45], and GPT-4 [46] has supported multi-\\nmodal input by integrating the visual information. This new\\nwave of technology would potentially lead to a prosperous\\necosystem of real-world applications based on LLMs. For\\ninstance, Microsoft 365 is being empowered by LLMs ( i.e.,\\nCopilot) to automate the office work, and OpenAI supports\\nthe use of plugins in ChatGPT for implementing special\\nfunctions.\\nDespite the progress and impact, the underlying prin-\\nciples of LLMs are still not well explored. Firstly, it is\\nmysterious why emergent abilities occur in LLMs, instead of\\nsmaller PLMs. As a more general issue, there lacks a deep,\\ndetailed investigation of the key factors that contribute to\\nthe superior abilities of LLMs. It is important to study when\\nand how LLMs obtain such abilities [47]. Although there are\\nsome meaningful discussions about this problem [31, 47],\\nmore principled investigations are needed to uncover the\\n‚Äúsecrets ‚Äú of LLMs. Secondly, it is difficult for the research\\ncommunity to train capable LLMs. Due to the huge de-\\nmand of computation resources, it is very costly to carry\\nout repetitive, ablating studies for investigating the effect\\nof various strategies for training LLMs. Indeed, LLMs are\\nmainly trained by industry, where many important training\\ndetails ( e.g., data collection and cleaning) are not revealed\\nto the public. Thirdly, it is challenging to align LLMs with\\nhuman values or preferences. Despite the capacities, LLMs\\nare also likely to produce toxic, fictitious, or harmful con-\\ntents. It requires effective and efficient control approaches\\nto eliminating the potential risk of the use of LLMs [46].\\nFaced with both opportunities and challenges, it needs\\nmore attention on the research and development of LLMs. In\\n3. https://www.bing.com/new', metadata={'source': 'data_input/llm_survey.pdf', 'page': 2})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untuk split file PDF menjadi chunk yang lebih kecil\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000, \n",
    "    chunk_overlap = 450,\n",
    "    separators=[\n",
    "                \"\\n\\n\",\n",
    "                \"\\n\",\n",
    "                \" \",\n",
    "                \".\",\n",
    "                \",\",\n",
    "                \"\\u200b\",  # zero-width space\n",
    "                \"\\uff0c\",  # full-width comma\n",
    "                \"\\u3001\",  # ideographic comma\n",
    "                \"\\uff0e\",  # full-width full stop\n",
    "                \"\\u3002\",  # ideographic full stop\n",
    "                \"\",\n",
    "            ])\n",
    "splits = text_splitter.split_documents(pdf_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding and Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASANI\\anaconda3\\envs\\dss_may2024\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# untuk membuat embedding\n",
    "from langchain_openai import OpenAIEmbeddings # embedding OpenAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings # embedding Google Generative AI\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings # embedding HuggingFace \n",
    "\n",
    "# untuk menyimpan embedding\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore_folder(documents, embedding, persist_directory):\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents = documents, \n",
    "        embedding = embedding,\n",
    "        persist_directory = persist_directory\n",
    "    )\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hanya perlu dijalankan pada saat pertama kali membuat embedding\n",
    "\n",
    "# vectorstore_open_ai = create_vectorstore_folder(\n",
    "#     documents = splits,\n",
    "#     embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\"),\n",
    "#     persist_directory = 'data_input/chroma_open_ai'\n",
    "# )\n",
    "\n",
    "# time spent: 48s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hanya perlu dijalankan pada saat pertama kali membuat embedding\n",
    "\n",
    "# vectorstore_gemini = create_vectorstore_folder(\n",
    "#     documents = splits,\n",
    "#     embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"),\n",
    "#     persist_directory = 'data_input/chroma_gemini'\n",
    "# )\n",
    "\n",
    "# time spent: 40.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hanya perlu dijalankan pada saat pertama kali membuat embedding\n",
    "\n",
    "# vectorstore_hf = create_vectorstore_folder(\n",
    "#     documents = splits,\n",
    "#     embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"),\n",
    "#     persist_directory = 'data_input/chroma_hugging_face'\n",
    "# )\n",
    "\n",
    "# time spent: 6m 24.6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memanggil embedding dari directory yang sudah disimpan\n",
    "\n",
    "vec_openai = Chroma(persist_directory = 'data_input/chroma_open_ai',\n",
    "                    embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-large\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_gemini = Chroma(persist_directory = 'data_input/chroma_gemini',\n",
    "                    embedding_function = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_hf = Chroma(persist_directory = 'data_input/chroma_hugging_face',\n",
    "                    embedding_function = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "\n",
    "# mempersiapkan prompt\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# untuk memasukkan pertanyaan\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# untuk menampilkan output yang diinginkan\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# menampilkan output secara rapi\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    You are the great assistant in understanding additional context\n",
    "\n",
    "    Use the following pieces of context to answer the question at the end.\n",
    "    Use the minimum of three sentences to answer the question. \n",
    "    Try your best to answer as complete as possible with easy style of English.\n",
    "    Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Helpful Answer:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_openai = vec_openai.as_retriever()\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0) # versi terbaru dari GPT\n",
    "\n",
    "openai_chain = (\n",
    "    {\"context\": retriever_openai | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LLaMA model family is a collection of models introduced by Meta AI in February 2023.\n",
      "The family consists of four sizes: 7B, 13B, 30B, and 65B. Since its release, LLaMA has\n",
      "gained significant attention from both the research and industry communities due to its\n",
      "excellent performance on various open benchmarks. It has become one of the most popular\n",
      "open language models. Many researchers have extended LLaMA models through instruction\n",
      "tuning or continual pretraining. Stanford Alpaca is one of the extended models, which is\n",
      "the first open instruct-following model fine-tuned based on LLaMA (7B). Other popular\n",
      "LLaMA variants include Vicuna, which is trained upon user-shared conversations. Thanks for\n",
      "asking!\n"
     ]
    }
   ],
   "source": [
    "neat_result = textwrap.fill(openai_chain.invoke('Describe about llaMa model family'), width=90)\n",
    "print(neat_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text provided does not contain information about when the Turing test was proposed.\n",
      "The Turing test, proposed by Alan Turing in 1950, is a method of inquiry in artificial\n",
      "intelligence for determining whether or not a computer is capable of human-like\n",
      "intelligence. However, this information is not mentioned in the given context. Thanks for\n",
      "asking!\n"
     ]
    }
   ],
   "source": [
    "neat_result = textwrap.fill(openai_chain.invoke('When was the Turing test proposed?'), width=90)\n",
    "print(neat_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The title of the paper is not explicitly mentioned in the provided context. However, there\n",
      "are several papers referenced throughout the text, each with different authors and titles.\n",
      "For example, one paper is titled \"Realtoxicityprompts: Evaluating neural toxic\n",
      "degeneration in language models\" by S. Gehman, S. Gururangan, M. Sap, Y. Choi, and N. A.\n",
      "Smith. Another is titled \"Virtualhome: Simulating household activities via programs\" by X.\n",
      "Puig, K. Ra, M. Boben, J. Li, T. Wang, S. Fidler, and A. Torralba. Without more specific\n",
      "information, it's impossible to determine the exact title of the paper in question. Thanks\n",
      "for asking!\n"
     ]
    }
   ],
   "source": [
    "neat_result = textwrap.fill(openai_chain.invoke('What is the title of the paper?'), width=90)\n",
    "print(neat_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The technical evolution of the GPT-series models has been a progressive journey. It\n",
      "started with GPT-1, which was developed based on a generative, decoder-only Transformer\n",
      "architecture. It used a hybrid approach of unsupervised pretraining and supervised fine-\n",
      "tuning. GPT-2 followed a similar architecture but increased the parameter scale to 1.5B\n",
      "and was trained with a large webpage dataset WebText. It introduced a probabilistic form\n",
      "for multi-task solving. GPT-3 scaled the model parameters to an even larger size of 175B\n",
      "and introduced the concept of in-context learning. The evolution continued with GPT-4 and\n",
      "other versions, each introducing new features and improvements. For example, ChatGPT was\n",
      "developed based on the powerful GPT model with specially optimized conversation\n",
      "capacities. The evolution of these models has been mainly based on the papers, blog\n",
      "articles, and official APIs from OpenAI. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "neat_result = textwrap.fill(openai_chain.invoke('How is the technical evolution of GPT-series model?'), width=90)\n",
    "print(neat_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chain(retriever, llm):\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | custom_rag_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_chain = create_chain(\n",
    "    retriever = vec_gemini.as_retriever(),\n",
    "    llm = ChatGoogleGenerativeAI(model = 'gemini-pro')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LLaMA model family is a group of language models that have been developed by Meta AI.\n",
      "The family includes models of varying sizes, from 7 billion parameters to 65 billion\n",
      "parameters. The models are trained on a massive dataset of text and code, and they can be\n",
      "used for a variety of natural language processing tasks, such as text generation,\n",
      "translation, and question answering. The LLaMA models have been shown to perform well on a\n",
      "variety of benchmarks, and they have been used in a number of commercial applications.\n",
      "Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "neat_result = textwrap.fill(gemini_chain.invoke('Describe about llaMa model family'), width=90)\n",
    "print(neat_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Turing test was proposed by Alan Turing in 1950. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "neat_result = textwrap.fill(gemini_chain.invoke('When was the Turing test proposed?'), width=90)\n",
    "print(neat_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry, I cannot answer the question. The provided context does not include any\n",
      "information about the title of the paper. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "neat_result = textwrap.fill(gemini_chain.invoke('What is the title of the paper?'), width=90)\n",
    "print(neat_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GPT-series models have evolved significantly over the years, with each iteration\n",
      "bringing improvements in performance and capabilities. GPT-1, released in 2018, was the\n",
      "first model in the series and set the foundation for the architecture and principles used\n",
      "in subsequent models. GPT-2, released in 2019, increased the parameter scale and was\n",
      "trained on a larger dataset, resulting in improved performance on a variety of language-\n",
      "related tasks. GPT-3, released in 2020, was a major leap forward in terms of size and\n",
      "capabilities, with 175 billion parameters and the ability to perform a wide range of\n",
      "tasks, including language generation, translation, and question answering. GPT-4, which is\n",
      "still under development, is expected to be even more powerful and versatile than its\n",
      "predecessors. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "neat_result = textwrap.fill(gemini_chain.invoke('How is the technical evolution of GPT-series model?'), width=90)\n",
    "print(neat_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASANI\\anaconda3\\envs\\dss_may2024\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "hf_chain = create_chain(\n",
    "    retriever = vec_hf.as_retriever(),\n",
    "    llm = HuggingFaceHub(\n",
    "        repo_id=\"declare-lab/flan-alpaca-large\",\n",
    "        task=\"text-generation\",\n",
    "        model_kwargs={\"temperature\":0.3, \"max_length\":1000}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LLaMA model family is a powerful language model family that is widely used in many\n",
      "applications. It is based on the LLaMA architecture, which is a supervised learning\n",
      "algorithm that is trained on a large dataset of language data. It is able to generate\n",
      "strong language understanding and generation abilities, compared to other variants. It is\n",
      "also able to learn from user-shared conversations, which makes it suitable for multimodal\n",
      "tasks.\n"
     ]
    }
   ],
   "source": [
    "neat_result = textwrap.fill(hf_chain.invoke('Describe about llaMa model family'), width=90)\n",
    "print(neat_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Turing test was proposed in 1947.\n"
     ]
    }
   ],
   "source": [
    "neat_result = textwrap.fill(hf_chain.invoke('When was the Turing test is proposed?'), width=90)\n",
    "print(neat_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The title of the paper is \"A Comprehensive Overview of Books and LLMs for Training\".\n"
     ]
    }
   ],
   "source": [
    "neat_result = textwrap.fill(hf_chain.invoke('What is the title of the paper?'), width=90)\n",
    "print(neat_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The technical evolution of GPT-series models is a gradual process of improvement. The\n",
      "model has evolved over time, with new features and improvements being added to the model.\n",
      "The model has also been improved by scaling the model parameters, which has allowed for a\n",
      "key capacity leap. The model has also been improved by incorporating more features and\n",
      "incorporating more advanced techniques. Finally, the model has been improved by\n",
      "incorporating more advanced techniques such as in-context learning and reinforcement\n",
      "learning.\n"
     ]
    }
   ],
   "source": [
    "neat_result = textwrap.fill(hf_chain.invoke('How is the technical evolution of GPT-series model?'), width=90)\n",
    "print(neat_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Chatbot-Like Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT 4o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dss_pdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
