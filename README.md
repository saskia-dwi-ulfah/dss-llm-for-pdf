# DSS May 2024: Efficient Information Extraction: Q&A and Summarization over PDF Documents using LLM

## Background

PDF file reports, as a form of written document, are used in many sectors. In practice, these reports often contain very detailed and comprehensive information. This makes the documents tend to be thick and complex, making it challenging to find specific information. The thickness and complexity of these reports are often due to the need to cover all relevant aspects and present data and analysis comprehensively to ensure that readers gain a complete understanding of the subject at hand.
With the development of artificial intelligence (AI) and machine learning (ML) technologies, we can streamline the search for information contained in tens or even hundreds of pages of PDF reports using large language models (LLMs). 

In this 3-day workshop, you will gain a brand new understanding of how we can extend LLMs' capabilities to enable efficient information retrieval from PDF documents. Starting with plain PDF documents, you will learn how to process these documents, serve them as additional contexts for LLMs, and eventually, this will answer all of your for the documents!

## Learning Outcomes

Upon completion of this workshop, you will be able to:
* Master the underlying basics of LLM.
* Implement LLM for real-world applications using LangChain.
* Understand the workflow of providing additional contexts for LLM.
* Develop skills in advanced document-handling techniques for information retrieval using LLM.

## Syllabus

**Python Programming Basics**
* Introduction to Python for data science
* Working with Python environment
* Python fundamental data types and data structures
* Understanding looping concept in Python
* Understanding the creation of Python function
* Understanding the usage of Python libraries

**The Fundamentals of LLM**
* The concept of generative AI 
* LLM as generative AI 
* Transformer architecture in a nutshell
* LLM capability, limitation, and consideration

**Introduction to LangChain**
* The big picture of LangChain concept and component
* API concept and setting for LangChain usage
* Demonstration of LLM usage with LangChain

**Case Study: Q&A and Summarization for PDF Document**
* The concept of RAG (retrieval augmented generation)
* Loading PDF documents using LangChain
* The concept of embedding for PDF documents
* Storing the embedding using a vector database
* Prompt creation for Q&A and summarization cases
* Employing LLM for information retrieval


